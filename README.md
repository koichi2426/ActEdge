# 最終目標

**AR空間上の汎用コンシェルジュを実現する。**
ユーザーの環境・状態・意図をリアルタイムに理解し、最適な行動を提示・支援するエージェントを、低消費電力でエッジ上に常時稼働させることを目指す。
参考イメージ：[YouTube動画](https://www.youtube.com/watch?v=RsXael79U5Y)

---

# 研究について

## 研究テーマ

**現状把握リアルタイム推論エンジンの研究**

## 研究背景・課題

汎用コンシェルジュには「受動的」と「能動的」な振る舞いがある。受動的振る舞いは、ユーザーの発言でLLMを起動すれば環境や状態を踏まえた推論が可能で、コストも現実的である。
一方、能動的振る舞いでは常時ユーザーと環境を考慮した推論が必要となり、LLMで毎回数百トークンのプロンプトを処理し続けるのはコストパフォーマンスが悪すぎる。
また、LLM以外の手法は習慣行動の推論には有効だが、観光地での興味対象の提案や混雑時のルート変更など、文脈依存の一時的な行動推論は困難である。

このように、常時・低コスト・高精度をすべて満たす推論エンジンは現状存在せず、汎用コンシェルジュの能動的振る舞いの実現には根本的な技術課題が存在する。


## 研究目的

個人の状態や環境に応じた行動を **超低消費電力(1mW以下)** でリアルタイムに推論するエンジンを開発し、**GPT-4o相当の推論精度**を実現すること。

## 提案手法

「環境情報」「ユーザー情報」から行動を予測する軽量な学習モデルを構築し、それをONNX形式に変換。Amazon EC2上で動作する推論APIサーバー（C++）によりモデルを呼び出し、API経由でリアルタイム推論を行う。

## 実装

実装は以下の2フェーズで構成されている：

* **モデル構築：**
  ユーザー／環境情報に基づく行動予測モデルを作成。CSVデータを前処理し、ラベル付き訓練データセットを生成。学習済みモデルをONNX形式に変換。

* **推論エンジン実装：**
  Amazon EC2上にC++製推論APIサーバーを構築し、ONNX形式のモデルを使用してリアルタイム推論を実行。S3バケットを利用してモデルやログを管理。

## ポスター

![image](https://github.com/user-attachments/assets/a5f8540b-5013-4243-bf44-e45266c67164)

---

必要であれば、英語版への翻訳やさらに短く要約したバージョンも可能です。
